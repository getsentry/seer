{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennmueng/Documents/code/timeseries-analysis-service/.venv/lib/python3.11/site-packages/tqdm-4.66.1-py3.11.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Flask '__main__'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['DATABASE_URL'] = \"postgresql+psycopg://root:seer@localhost:5433/seer\"\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"ai-autofix-dev\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('autofix')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "from seer.bootup import bootup\n",
    "\n",
    "bootup(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennmueng/Documents/code/timeseries-analysis-service/.venv/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from seer.automation.autofix.models import RepoDefinition\n",
    "from seer.automation.codebase.codebase_index import CodebaseIndex\n",
    "\n",
    "repo_definition = RepoDefinition(provider=\"github\", owner=\"getsentry\", name=\"seer\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"../models/autofix_embeddings_v0\", trust_remote_code=True)\n",
    "embedding_model.max_seq_length = 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading repository to /var/folders/c8/ljt8gc_13j30r7lt_p842hrw0000gn/T/getsentry-seer_40b62d5ef954055e59fb34be110eac77a408bb8c8kuwy_2e/repo\n",
      "Loaded repository to /var/folders/c8/ljt8gc_13j30r7lt_p842hrw0000gn/T/getsentry-seer_40b62d5ef954055e59fb34be110eac77a408bb8c8kuwy_2e/repo\n",
      "Read 4 documents:\n",
      "  yaml: 2\n",
      "  markdown: 1\n",
      "  bash: 1\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 1/4\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 2/4\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 3/4\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 4/4\n",
      "Embedding 37 chunks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Batches: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "256it [00:10, 24.00it/s]              \n",
      "Embedded 37 chunks\n",
      "Processed 37 chunks\n",
      "Saved workspace for namespace 1\n",
      "Create Step: Inserted 37 chunks into the database\n",
      "Loaded codebase index for getsentry/seer, with existing data\n"
     ]
    }
   ],
   "source": [
    "codebase = CodebaseIndex.create(\n",
    "    1,\n",
    "    1,\n",
    "    repo_definition,\n",
    "    uuid.uuid4(),\n",
    "    embedding_model,\n",
    "    sha='40b62d5ef954055e59fb34be110eac77a408bb8c'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded codebase index for getsentry/seer, with existing data\n"
     ]
    }
   ],
   "source": [
    "codebase = CodebaseIndex.from_repo_definition(1, 1, repo_definition, '40b62d5ef954055e59fb34be110eac77a408bb8c', None, uuid.uuid4(), embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting file contents for LICENSE.md in getsentry/seer on sha 40b62d5ef954055e59fb34be110eac77a408bb8c\n",
      "Document chunking took 0.02 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n",
      "Document chunking took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[LICENSE.md]\n",
       " ### Disclaimer,\n",
       " [LICENSE.md]\n",
       " ### Licensor (\"We\"),\n",
       " [LICENSE.md]\n",
       " ### Redistribution,\n",
       " [LICENSE.md]\n",
       " IN NO EVENT WILL WE HAVE ANY LIABILITY TO YOU ARISING OUT OF OR RELATED TO THE\n",
       " SOFTWARE, INCLUDING INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES,\n",
       " EVEN IF WE HAVE BEEN INFORMED OF THEIR POSSIBILITY IN ADVANCE.,\n",
       " [LICENSE.md]\n",
       " ## Notice,\n",
       " [LICENSE.md]\n",
       " You may obtain a copy of the License at,\n",
       " [LICENSE.md]\n",
       " 1. for your internal use and access;\n",
       " \n",
       " 2. for non-commercial education;\n",
       " \n",
       " 3. for non-commercial research; and\n",
       " \n",
       " 4. in connection with professional services that you provide to a licensee\n",
       "    using the Software in accordance with these Terms and Conditions.,\n",
       " [LICENSE.md]\n",
       " http://www.apache.org/licenses/LICENSE-2.0,\n",
       " [LICENSE.md]\n",
       " ### License Grant,\n",
       " [LICENSE.md]\n",
       " ## Grant of Future License]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebase.query(\"LIABILITY\", top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaned up workspace for namespace 1\n"
     ]
    }
   ],
   "source": [
    "codebase.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document chunking took 0.00 seconds\n",
      "Embedding 1 chunks...\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "256it [00:00, 258.93it/s]            \n",
      "Embedded 1 chunks\n"
     ]
    }
   ],
   "source": [
    "from seer.automation.models import FileChange\n",
    "\n",
    "\n",
    "codebase.store_file_change(FileChange(\n",
    "    change_type='create',\n",
    "    path=\"src/booga.py\",\n",
    "    new_snippet=\"BOoga_boogas\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebase.storage.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
