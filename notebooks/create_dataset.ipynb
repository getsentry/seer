{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import field_serializer, BaseModel\n",
    "from github.Commit import Commit\n",
    "from typing import Any\n",
    "from pydantic import ConfigDict, field_validator\n",
    "\n",
    "from seer.automation.autofix.models import IssueDetails, EventDetails\n",
    "\n",
    "class EvalItem(BaseModel):\n",
    "    raw_data: dict[str, Any]\n",
    "    commit: Commit\n",
    "    issue: IssueDetails\n",
    "    event: EventDetails\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True\n",
    "    )\n",
    "\n",
    "    @field_serializer('commit')\n",
    "    def serialize_commit(self, commit: Commit, _info):\n",
    "        return commit.sha\n",
    "    \n",
    "    @field_validator('commit', mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_commit(cls, commit: Commit | str):\n",
    "        return commit if isinstance(commit, Commit) else repo.get_commit(commit)\n",
    "    \n",
    "class EvalItemWithDiff(EvalItem):\n",
    "    diff: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "eval_file = '../data/full_eval_autofix_240314.json'\n",
    "\n",
    "with open(eval_file, 'r') as file:\n",
    "    tmp_autofix_data = json.load(file)\n",
    "\n",
    "eval_data = [EvalItemWithDiff.model_validate(item) for item in tmp_autofix_data]\n",
    "\n",
    "print(f\"Loaded {len(eval_data)} eval items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset to langsmith:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "# Inputs are provided to your model, so it know what to generate\n",
    "dataset_inputs = [item.model_dump(mode='json') for item in eval_data]\n",
    "\n",
    "# Outputs are provided to the evaluator, so it knows what to compare to\n",
    "# Outputs are optional but recommended.\n",
    "dataset_outputs = [{ \"diff\": item.diff } for item in eval_data]\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Autofix Eval Full 240314\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Autofix full eval made from mapping sentry <-> github commits for sentry project\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=dataset_inputs,\n",
    "    outputs=dataset_outputs,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
