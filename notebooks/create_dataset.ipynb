{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create a dataset from Sentry Issues <-> Github commits that reference a sentry issue and save it to langsmith."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the github client and instantiate the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "from github import Github\n",
    "from github.Auth import Token\n",
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from pydantic import (\n",
    "    AliasChoices,\n",
    "    AliasGenerator,\n",
    "    BaseModel,\n",
    "    ConfigDict,\n",
    "    Field,\n",
    "    ValidationError,\n",
    "    field_validator,\n",
    "    field_serializer\n",
    ")\n",
    "\n",
    "# from pydantic import field_serializer, BaseModel\n",
    "from github.Commit import Commit\n",
    "from typing import Any, Optional\n",
    "from pydantic import ConfigDict, field_validator\n",
    "\n",
    "from seer.automation.autofix.models import IssueDetails\n",
    "from seer.automation.models import EventDetails\n",
    "\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from github.Commit import Commit\n",
    "from github.File import File\n",
    "\n",
    "github = Github(auth=Token(token=os.environ.get('GITHUB_TOKEN')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_resolved_issues(organization_slug=\"sentry\", project_slug=\"sentry\", cursor=None):\n",
    "    url = f\"https://sentry.io/api/0/projects/{organization_slug}/{project_slug}/issues/?query=is:resolved error.type:TypeError\"\n",
    "\n",
    "    # if cursor: \n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {os.environ.get('SENTRY_AUTH_TOKEN')}\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    if \"detail\" in result:\n",
    "        raise Exception(result[\"detail\"])\n",
    "\n",
    "    return result, response.links[\"next\"]\n",
    "\n",
    "def auth_headers(auth_token=None, auth_cookie=None):\n",
    "    auth_token = auth_token if auth_token else os.environ.get('SENTRY_AUTH_TOKEN')\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {auth_token}\"\n",
    "    }\n",
    "    if auth_cookie:\n",
    "        headers[\"Cookie\"] = auth_cookie\n",
    "    return headers    \n",
    "\n",
    "def get_issue_by_id(issue_id, organization_slug=\"sentry\", auth_token=None, auth_cookie=None):\n",
    "    url = (\n",
    "        f\"https://sentry.io/api/0/organizations/{organization_slug}/issues/{issue_id}/\"\n",
    "    )\n",
    "\n",
    "    headers = auth_headers(auth_token, auth_cookie)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    issue = response.json()\n",
    "\n",
    "    if \"detail\" in issue and issue[\"detail\"] == \"The requested resource does not exist\":\n",
    "        raise Exception(f\"Could not find issue with id {issue_id}\")\n",
    "\n",
    "    return issue\n",
    "\n",
    "\n",
    "def get_issue_id_from_short_id(short_id, organization_slug=\"sentry\", auth_token=None, auth_cookie=None):\n",
    "    url = f\"https://sentry.io/api/0/organizations/{organization_slug}/shortids/{short_id}/\"\n",
    "    headers = auth_headers(auth_token, auth_cookie)\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    result = response.json()\n",
    "\n",
    "    if ( \n",
    "        \"detail\" in result\n",
    "        and result[\"detail\"] == \"The requested resource does not exist\"\n",
    "    ):\n",
    "        raise Exception(f\"Could not find issue with short id {short_id}\")\n",
    "\n",
    "    return result[\"groupId\"]\n",
    "\n",
    "\n",
    "def get_details_for_issue(issue_id=None, short_id=None, organization_slug=\"sentry\", auth_token=None, auth_cookie=None):\n",
    "    if issue_id is None and short_id is None:\n",
    "        raise Exception(\"Either issue_id or short_id must be provided\")\n",
    "\n",
    "    if short_id:\n",
    "        issue_id = get_issue_id_from_short_id(short_id, organization_slug, auth_token, auth_cookie)\n",
    "    issue = get_issue_by_id(issue_id, organization_slug, auth_token, auth_cookie)\n",
    "    \n",
    "    if 'id' not in issue:\n",
    "        if issue['detail'] == 'You do not have permission to perform this action.':\n",
    "            # Its possible that the token is expired. Prompt for token and retry\n",
    "            auth_cookie = input('Sentry sudo cookie')\n",
    "            if short_id:\n",
    "                issue_id = get_issue_id_from_short_id(short_id, organization_slug, auth_token, auth_cookie)\n",
    "            issue = get_issue_by_id(issue_id, organization_slug, auth_token, auth_cookie)\n",
    "            if 'id' not in issue:\n",
    "                raise Exception(issue)\n",
    "        else:\n",
    "            raise Exception(issue)\n",
    "            \n",
    "    url = f\"https://sentry.io/api/0/organizations/{organization_slug}/issues/{issue['id']}/events/?full=true\"\n",
    "    headers = auth_headers(auth_token, auth_cookie)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    events = response.json()\n",
    "    return auth_cookie, dict(\n",
    "        **issue,\n",
    "        events=events[:1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_details_for_issue(issue_id=5206388570, organization_slug='seria-ati'))\n",
    "print(get_details_for_issue(issue_id=5177147602, organization_slug='sentry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalItem(BaseModel):\n",
    "    raw_data: dict[str, Any]\n",
    "    organization_id: int\n",
    "    project_id: int\n",
    "    repo_name: Optional[str] = None\n",
    "    commit_hash: Optional[str] = None\n",
    "    # Field order matters as commit is dependent on repo_name and commit_hash, it should come later down the order.\n",
    "    commit: Commit | str\n",
    "    issue: IssueDetails\n",
    "    event: EventDetails\n",
    "    \n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True\n",
    "    )\n",
    "    \n",
    "    @field_serializer('commit')\n",
    "    def serialize_commit(self, commit: Commit, _info):\n",
    "        return commit.sha\n",
    "    \n",
    "    @field_validator('commit', mode=\"after\")\n",
    "    @classmethod\n",
    "    def validate_commit(cls, commit: Commit | str, values, **kwargs):\n",
    "        if isinstance(commit, Commit):\n",
    "            return commit\n",
    "        if 'repo_name' in values.data and values.data['repo_name'] is not None :\n",
    "            repo_name = values.data['repo_name']\n",
    "        else:\n",
    "            repo_name = 'getsentry/sentry'\n",
    "            values.data['repo_name'] = repo_name\n",
    "        repo = github.get_repo(repo_name)\n",
    "        values.data['commit_hash'] = commit\n",
    "        return repo.get_commit(commit)\n",
    "        \n",
    "class EvalItemWithDiff(EvalItem):\n",
    "    diff: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(repo, since):\n",
    "    \"\"\"\n",
    "        Get all the commits from repo for a timeframe.\n",
    "    \"\"\"\n",
    "    days_ago = datetime.datetime.now() - timedelta(days=since)\n",
    "    print('Querying for commits')\n",
    "    all_commits = repo.get_commits(since=days_ago)\n",
    "    # all_commits = [commit for commit in commits]\n",
    "    print('Total commits in this timeframe: ', all_commits.totalCount)\n",
    "    return all_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commits_with_sentry_issue(all_commits):\n",
    "    \"\"\"\n",
    "        Filter it down to only commits with sentry issues.\n",
    "    \"\"\"\n",
    "    # Gets the commits with an id or url to a sentry issue\n",
    "    with_id_or_url = []\n",
    "\n",
    "    with tqdm(all_commits, total=all_commits.totalCount, desc='Find Commits That Fix Issues', unit='Commit') as pbar:\n",
    "        with tqdm(desc='Positive', unit='Commit') as ctr1:\n",
    "            with tqdm(desc='Negative', unit='Commit') as ctr2:\n",
    "                for commit in pbar:\n",
    "                    if 'SENTRY-' in commit.commit.message or 'https://sentry.sentry.io/issues/' in commit.commit.message:\n",
    "                        # Extracts the short id or id from the commit message\n",
    "                        message = commit.commit.message\n",
    "                        issue_short_id_match = re.findall(r'SENTRY-.{4}', message)\n",
    "                        issue_short_id = issue_short_id_match[0] if issue_short_id_match else None\n",
    "                        issue_url = re.findall(r'https://sentry.sentry.io/issues/\\d+', message)\n",
    "                        issue_id = issue_url[0].split('/')[-1] if issue_url else None                \n",
    "                        if issue_short_id or issue_id:\n",
    "                            with_id_or_url.append((1, 1, 'getsentry/sentry', commit.sha, commit, issue_short_id, issue_id, 'sentry'))\n",
    "                            ctr1.update(1)\n",
    "                        else:\n",
    "                            ctr2.update(1)\n",
    "                    else:\n",
    "                        ctr2.update(1)\n",
    "                        \n",
    "    return with_id_or_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_items_for_sentry(with_id_or_url, auth_token=None, auth_cookie=None):\n",
    "    \"\"\"\n",
    "        Populate into eval items.\n",
    "    \"\"\"\n",
    "    eval_items: list[EvalItem] = []\n",
    "    skipped_items: list[EvalItem] = []\n",
    "    error_count = 0\n",
    "    errors = []\n",
    "    prev_auth_cookie = auth_cookie\n",
    "    with tqdm(total=len(with_id_or_url), desc='Get issue details') as pbar: \n",
    "        for org_id, project_id, repo_name, commit_hash, commit, short_id, issue_id, org_slug in with_id_or_url:\n",
    "            try:\n",
    "                auth_cookie, issue = get_details_for_issue(issue_id=issue_id, short_id=short_id, organization_slug=org_slug, auth_token=auth_token, auth_cookie=auth_cookie)\n",
    "                if auth_cookie != prev_auth_cookie:\n",
    "                    print(\"Cookie changed\")\n",
    "                    prev_auth_cookie = auth_cookie\n",
    "                issue_details = IssueDetails.model_validate(issue)\n",
    "                event_details = EventDetails.from_event(issue_details.events[0])\n",
    "    \n",
    "                eval_item = EvalItem(\n",
    "                    organization_id=org_id,\n",
    "                    project_id=project_id,\n",
    "                    repo_name=repo_name,\n",
    "                    commit_hash=commit_hash,\n",
    "                    commit=commit,\n",
    "                    raw_data=issue,\n",
    "                    issue=issue_details,\n",
    "                    event=event_details\n",
    "                )\n",
    "    \n",
    "                if len(event_details.exceptions) == 0:\n",
    "                    skipped_items.append(eval_item)\n",
    "                    continue\n",
    "    \n",
    "                eval_items.append(eval_item)\n",
    "            except Exception as e:\n",
    "                if 'You do not have permission to perform this action.' in repr(e):\n",
    "                    abort = input(\"Auth token is not working. Abort (yes/no/retry)?\")\n",
    "                    if abort.lower() == 'yes':\n",
    "                        break\n",
    "                else:\n",
    "                    print(repr(e))\n",
    "                errors.append({type(e):e})\n",
    "                error_count += 1\n",
    "            finally:\n",
    "                pbar.update(1)\n",
    "    \n",
    "    print('Total eval items:', len(eval_items))\n",
    "    print('Total skipped items (no exceptions in event details):', len(skipped_items))\n",
    "    print('Total errors:', error_count)\n",
    "    if len(errors) > 0:\n",
    "        print('Errors:')\n",
    "        print('------------------------------')\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "            print('------------------------------')\n",
    "    return eval_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4-0125-preview\")\n",
    "\n",
    "# Methods for Prompt GPT so we can filter it down to only issues that are \"actionable\" \n",
    "# which means in this case, given a sentry issue, it should be evident \n",
    "# what the developer should do to fix it.\n",
    "\n",
    "def file_patch_to_str(file: File):\n",
    "    return f\"[{file.filename}]\\n{file.patch}\"\n",
    "\n",
    "\n",
    "def explain_changes(error_msg, stack_str, commit_message, files_str):\n",
    "    response = model.invoke(\n",
    "        f\"\"\"<error_message>\n",
    "{error_msg}\n",
    "</error_message>\n",
    "<stacktrace>\n",
    "{stack_str}\n",
    "</stacktrace>\n",
    "\n",
    "A software engineer then created the following changes in a commit to fix the above issue:\n",
    "<commit_message>\n",
    "{commit_message}\n",
    "</commit_message>\n",
    "<changes>\n",
    "{files_str}\n",
    "</changes>\n",
    "\n",
    "How would you describe the solution to the error in a short summary. Also describe what the root cause of the problem ended up being.\"\"\"\n",
    "    )\n",
    "\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def determine_actionability(error_msg, stack_str, solution):\n",
    "    response = model.invoke(\n",
    "        f\"\"\"Given the provided information:\n",
    "<information>\n",
    "<error_message>\n",
    "{error_msg}\n",
    "</error_message>\n",
    "<stacktrace>\n",
    "{stack_str}\n",
    "</stacktrace>\n",
    "</information>\n",
    "\n",
    "<expected_solution>\n",
    "{solution}\n",
    "</expected_solution>\n",
    "\n",
    "Based on the error message and stacktrace, can the solution be inferred from the information given and access to reading the codebase? Why or why not?\n",
    "Answer in the format:<response>yes/no</response><reason>reason for the response</reason>\"\"\"\n",
    "    )\n",
    "    comatch = re.match(r\"<response>(.*?)</response>\", response.content)\n",
    "    if comatch and \"yes\" in comatch.group(1).lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_fixable_items(eval_items):\n",
    "    fixable_items: list[EvalItem] = []\n",
    "    panel_n = 5\n",
    "    with tqdm(eval_items, desc='Check fixability', total=len(eval_items)) as pbar:\n",
    "        with tqdm(desc='Fixable') as ctr1:\n",
    "            with tqdm(desc='Not Fixable') as ctr2:\n",
    "                for eval_item in pbar:\n",
    "                    issue_details = eval_item.issue\n",
    "                    stacktrace = eval_item.event.exceptions[0].stacktrace            \n",
    "                    stacktrace_str = stacktrace.to_str(max_frames=64)\n",
    "                    commit = eval_item.commit\n",
    "                    files = commit.files\n",
    "                    files_str = \"\\n\".join([file_patch_to_str(file) for file in files])\n",
    "            \n",
    "                    explain_result = explain_changes(\n",
    "                        issue_details.title, stacktrace_str, commit.commit.message, files_str\n",
    "                    )\n",
    "            \n",
    "                    actionability_results = []\n",
    "                    final_result = False\n",
    "                    for _ in range(panel_n):\n",
    "                        actionability_result = determine_actionability(issue_details.title, stacktrace_str, explain_result)\n",
    "                        actionability_results.append(actionability_result)\n",
    "                        true_count = actionability_results.count(True)\n",
    "                        false_count = actionability_results.count(False)\n",
    "                        if true_count > panel_n / 2:\n",
    "                            final_result = True\n",
    "                            break\n",
    "                        if false_count > panel_n / 2:\n",
    "                            final_result = False\n",
    "                            break\n",
    "                    \n",
    "                    if final_result:\n",
    "                        fixable_items.append(eval_item)\n",
    "                        ctr1.update(1)\n",
    "                    else:\n",
    "                        ctr2.update(1)\n",
    "                        \n",
    "    print('Total fixable items:', len(fixable_items))\n",
    "    print('Total non-fixable items:', len(eval_items) - len(fixable_items))\n",
    "    return fixable_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diff(fixable_items):\n",
    "    \"\"\"\n",
    "        Populate the eval items that are fixable with their expected diffs\n",
    "    \"\"\"\n",
    "    final_eval_items: list[EvalItemWithDiff] = []\n",
    "    for item in tqdm(fixable_items, desc='Loading Diff Info'):\n",
    "        repo = github.get_repo(item.repo_name)\n",
    "        comparison = repo.compare(item.commit.commit.parents[0].sha, item.commit.sha)\n",
    "        \n",
    "        requester = repo._requester\n",
    "        headers = {\n",
    "            \"Authorization\": f\"{requester._Requester__auth.token_type} {requester._Requester__auth.token}\",  # type: ignore\n",
    "            \"User-Agent\": requester._Requester__userAgent,  # type: ignore\n",
    "        }\n",
    "        diff_data = requests.get(comparison.diff_url, headers=headers).content.decode('utf-8')\n",
    "    \n",
    "        final_item = EvalItemWithDiff.model_validate(dict(\n",
    "            **dict(item),\n",
    "            diff=diff_data\n",
    "        ))\n",
    "        final_eval_items.append(final_item)\n",
    "    return final_eval_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_items(items: list[EvalItem], filename: str):\n",
    "    serialized_items = [item.model_dump(mode='json') for item in items]\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(serialized_items, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fixable Items From Sentry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixable_issues_from_sentry(since=90, op_file='../data/eval_items.json'):\n",
    "    repo = github.get_repo('getsentry/sentry')\n",
    "    all_commits = get_commits(repo, since)\n",
    "    with_id_or_url = commits_with_sentry_issue(all_commits)\n",
    "    eval_items = eval_items_for_sentry(with_id_or_url)\n",
    "    fixable_items = get_fixable_items(eval_items)\n",
    "    final_eval_items = add_diff(fixable_items)\n",
    "    print('Total final eval items:', len(final_eval_items))\n",
    "    dump_items(final_eval_items, op_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "def delete_if_exists(client, dataset_name):\n",
    "    if client.has_dataset(dataset_name=dataset_name):\n",
    "        deleted = False\n",
    "        print(f'Dataset {dataset_name} exists already. Clearing it first.')\n",
    "        for cur in client.list_datasets():\n",
    "            if cur.name == dataset_name:\n",
    "                client.delete_dataset(dataset_id=str(cur.id))\n",
    "                deleted = True\n",
    "        if not deleted:\n",
    "            raise Exception('Failed to find the dataset to delete')\n",
    "\n",
    "def create_langsmith_dataset(items, num_entries, dataset_name, description, overwrite=False):    \n",
    "    client = Client()\n",
    "    if overwrite:\n",
    "        delete_if_exists(client, dataset_name)\n",
    "        \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description)\n",
    "    errors = []\n",
    "    with tqdm(desc='Uploading Example', total=num_entries) as pbar:\n",
    "        with tqdm(desc='Errors') as ctr1:\n",
    "            uploaded = 0\n",
    "            cur_index = 0\n",
    "            while uploaded < num_entries and cur_index < len(items):\n",
    "                item = EvalItemWithDiff.model_validate(items[cur_index])\n",
    "                cur_index = cur_index + 1\n",
    "                input = item.model_dump(mode='json')\n",
    "                output = { \"diff\": item.diff }\n",
    "                try:            \n",
    "                    client.create_example(\n",
    "                        inputs=input, \n",
    "                        outputs=output,\n",
    "                        dataset_id=dataset.id)\n",
    "                    pbar.update(1)\n",
    "                    uploaded = uploaded + 1\n",
    "                except Exception as e:\n",
    "                    ctr1.update(1)\n",
    "                    errors.append({type(e):e})\n",
    "\n",
    "    print(f'Uploaded {uploaded} samples to dataset')\n",
    "    if len(errors) > 0:\n",
    "        print('-------------Errors-------------')\n",
    "        for e in errors:\n",
    "            print(e, '----------------------')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_langsmith_dataset(\n",
    "#     final_eval_items, \n",
    "#     \"Autofix Eval Full 240314\", \n",
    "#     \"Autofix full eval made from mapping sentry <-> github commits for sentry project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fixable Items From Issues Related To Open Source Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def os_commits_with_sentry_issue(sentry_org=False, limit=None):\n",
    "    org_predicate = 'organization_id = 1 AND project_id = 1' if sentry_org else 'organization_id <> 1'\n",
    "    limit_clause = f'LIMIT {limit}' if limit else ''\n",
    "    \n",
    "         \n",
    "    bq_sql = f\"\"\"\n",
    "        WITH status_info AS (\n",
    "          SELECT * FROM getsentry.sentry_grouphistory\n",
    "          WHERE status IN (12, 13)\n",
    "            AND {org_predicate}\n",
    "            -- AND organization_id <> 1\n",
    "            -- AND organization_id = 1 AND project_id = 1\n",
    "        ),\n",
    "        commit_ids AS (\n",
    "          SELECT group_id, linked_id, project_id\n",
    "          FROM getsentry.sentry_grouplink \n",
    "          WHERE linked_type = 1 AND relationship = 1 \n",
    "            AND group_id IN (SELECT distinct group_id FROM status_info)\n",
    "        )\n",
    "        SELECT commits.organization_id, \n",
    "          org.name as organization_name, org.slug as organization_slug,\n",
    "          commit_ids.project_id, commit_ids.group_id, repos.name, \n",
    "          commits.author_id, commits.date_added, \n",
    "          commits.key, commits.message, \n",
    "          commits.repository_id\n",
    "        FROM getsentry.sentry_commit AS commits\n",
    "        JOIN getsentry.sentry_repository AS repos\n",
    "          ON commits.organization_id = repos.organization_id AND commits.repository_id = repos.id\n",
    "        JOIN `tmp_ram.github_open_source_repos` AS oss_repos \n",
    "          ON repos.name = oss_repos.name\n",
    "        JOIN commit_ids \n",
    "          ON  commits.id = commit_ids.linked_id\n",
    "        JOIN `getsentry.sentry_organization` AS org\n",
    "          ON commits.organization_id = org.id  \n",
    "        WHERE commits.id IN (SELECT distinct linked_id FROM commit_ids) ORDER BY date_added DESC\n",
    "        -- LIMIT 5\n",
    "        {limit_clause}\n",
    "    \"\"\"\n",
    "    results = bigquery_client.query(bq_sql).to_dataframe()\n",
    "    print(f'Retrieved {results.shape[0]} commits associated with resolved issues')\n",
    "    with_id_or_url = []\n",
    "    failed = []\n",
    "\n",
    "    with (\n",
    "        tqdm(results.iterrows(), total=results.shape[0]) as pbar,\n",
    "        tqdm(desc='Successful') as ctr1,\n",
    "        tqdm(desc='Failed') as ctr2):\n",
    "        for i, row in pbar:\n",
    "            cur_hash = row['key']\n",
    "            repo_name = row['name']\n",
    "            pbar.set_description(f'Commit {cur_hash[0:8]} from {repo_name}')\n",
    "            try:\n",
    "                repo = github.get_repo(repo_name)\n",
    "                commit = repo.get_commit(cur_hash)\n",
    "                with_id_or_url.append((row['organization_id'], row['project_id'], repo_name, cur_hash, commit, None, row['group_id'], row['organization_slug']))\n",
    "                ctr1.update(1)\n",
    "            except Exception as e:\n",
    "                failed.append([repo_name, cur_hash, e])\n",
    "                ctr2.update(1)\n",
    "\n",
    "    if len(failed) > 0:\n",
    "        print('Errors:')\n",
    "        print('-----------------------------')\n",
    "        for repo_name, cur_hash, e in failed:\n",
    "            print(f'Error getting commit details for {cur_hash} from repo {repo_name}: {e}')\n",
    "            print('-----------------------------')\n",
    "        \n",
    "    return with_id_or_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from(filenames, items_have_diff=True, add_diff_if_missing=True):\n",
    "    all_items = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            if items_have_diff:\n",
    "                items = [EvalItemWithDiff.model_validate(cur) for cur in tqdm(data, desc='Validating Data')]\n",
    "            else:\n",
    "                items = [EvalItem.model_validate(cur) for cur in tqdm(data, desc='Validating Data')]\n",
    "                if add_diff_if_missing:\n",
    "                    items = add_diff(items)\n",
    "            all_items = all_items + items\n",
    "    return all_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_fixable_issues(op_file='../data/eval_items.json', eval_items_file=None, needs_su=False, sentry_org=False, limit=None, load_cached=False, skip_fixable_check=False):\n",
    "    if load_cached:\n",
    "        #load from eval_items_file\n",
    "        eval_items = load_data_from([eval_items_file], items_have_diff=False, add_diff_if_missing=False)\n",
    "    else:\n",
    "        with_id_or_url = os_commits_with_sentry_issue(sentry_org, limit)\n",
    "        if needs_su:\n",
    "            eval_items = eval_items_for_sentry(with_id_or_url, auth_token=None, auth_cookie='dummy_cookie')\n",
    "        else:\n",
    "            eval_items = eval_items_for_sentry(with_id_or_url)\n",
    "        if eval_items_file:\n",
    "            print(f'Saving intermediate results (before running ChatGPT based filtering) to {eval_items_file}.')\n",
    "            dump_items(eval_items, eval_items_file)\n",
    "    if not skip_fixable_check:\n",
    "        fixable_items = get_fixable_items(eval_items)\n",
    "        final_eval_items = add_diff(fixable_items)\n",
    "        print('Total final eval items:', len(final_eval_items))\n",
    "        dump_items(final_eval_items, op_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Issues And Commits From Sentry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762c1445c0fb4ea08e48e15470b3fcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Data:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52df1d2f362e4f259eb78a8b797670b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Check fixability:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8544580faa08442b98db092894def50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fixable: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985969c41ab14609a82ab9ce04d4198b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Not Fixable: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fixable items: 88\n",
      "Total non-fixable items: 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7585c5ecf06645648b049b61382f358a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Diff Info:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total final eval items: 88\n"
     ]
    }
   ],
   "source": [
    "# Step 1: load data from sentry, filter and save to intermediate file.\n",
    "# get_os_fixable_issues(op_file='../data/eval_sentry_items_from_db_apr_23_90_days.json', \n",
    "#                       eval_items_file='../data/inter_eval_sentry_items_from_db_apr_23_90_days.json',\n",
    "#                       needs_su=False, sentry_org=True, limit=None, \n",
    "#                       load_cached=False, skip_fixable_check=True)\n",
    "\n",
    "# Step 2: Load from intermendiate file, check if fixable using ChatGPT and save\n",
    "# get_os_fixable_issues(op_file='../data/eval_sentry_items_from_db_apr_23_90_days.json', \n",
    "#                       eval_items_file='../data/inter_eval_sentry_items_from_db_apr_23_90_days.json',\n",
    "#                       needs_su=False, sentry_org=True, limit=None, load_cached=True, skip_fixable_check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Issues And Commits From Open Source Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafb076684164d9d8d70674b6c733e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Data:   0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb0ff517973471a8132fa81fe6d268d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Check fixability:   0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b7efa9da404f61adebe2ed4184f536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fixable: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c73bd82c7d6472db69e66b5e64018ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Not Fixable: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fixable items: 99\n",
      "Total non-fixable items: 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1ea4682aa94ea6a2827b886f4bcc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Diff Info:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total final eval items: 99\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: load data from sentry, filter and save to intermediate file.\n",
    "# get_os_fixable_issues(op_file='../data/eval_os_items_from_db_apr_23_90_days.json', \n",
    "#                       eval_items_file='../data/inter_eval_os_items_from_db_apr_23_90_days.json',\n",
    "#                       needs_su=True, sentry_org=False, limit=None,\n",
    "#                       load_cached=False, skip_fixable_check=True)\n",
    "\n",
    "# Step 2: Load from intermendiate file, check if fixable using ChatGPT and save\n",
    "# get_os_fixable_issues(op_file='../data/eval_os_items_from_db_apr_23_90_days.json', \n",
    "#                       eval_items_file='../data/inter_eval_os_items_from_db_apr_23_90_days.json',\n",
    "#                       needs_su=True, sentry_org=False, limit=None,\n",
    "#                       load_cached=True, skip_fixable_check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Presaved JSON Data To LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(all_items, num_entries):\n",
    "    indices = list(range(len(all_items)))\n",
    "    random.shuffle(indices)\n",
    "    selected = []\n",
    "    for idx in indices[0:num_entries]:\n",
    "        selected.append(all_items[idx])\n",
    "    return selected\n",
    "    \n",
    "def save_langsmith(ds_name, filenames, num_entries=None, shuffle=True, overwrite=False):\n",
    "    all_items = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            all_items = all_items + data\n",
    "    \n",
    "    print(f'Loaded {len(all_items)} items')\n",
    "    if shuffle:\n",
    "        random.shuffle(all_items)\n",
    "        \n",
    "    create_langsmith_dataset(\n",
    "        all_items,\n",
    "        num_entries,\n",
    "        ds_name,\n",
    "        f\"{num_entries} issues with related github commits for autofix validation\",\n",
    "        overwrite=overwrite)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 187 items\n",
      "Dataset Autofix Eval 100 240423 exists already. Clearing it first.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdfcd493738452698c0552721d9d3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Example:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6a3bf5d44f458ab579d06cee5ba678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Errors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 100 samples to dataset\n",
      "-------------Errors-------------\n",
      "{<class 'requests.exceptions.HTTPError'>: HTTPError('500 Server Error: Internal Server Error for url: https://api.smith.langchain.com/examples', '{\"detail\":\"Internal server error\"}')} ----------------------\n"
     ]
    }
   ],
   "source": [
    "save_langsmith(\n",
    "    ds_name=\"Autofix Eval 100 240423\", \n",
    "    filenames=['../data/eval_os_items_from_db_apr_23_90_days.json', '../data/eval_sentry_items_from_db_apr_23_90_days.json'], \n",
    "    num_entries=100,\n",
    "    shuffle=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Smaller Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 187 items\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd031f298874654972d5edab6cec66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Example:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca284cf82dc40498171db8c166618bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Errors: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3 samples to dataset\n"
     ]
    }
   ],
   "source": [
    "save_langsmith(\n",
    "    ds_name=\"Autofix Eval 3 240423\", \n",
    "    # filenames=['../data/deleteme_three.json']\n",
    "    # filenames=['../data/eval_os_items_from_db_apr_23_90_days.json'],\n",
    "    # filenames=['../data/oss_one.json'],\n",
    "    filenames=['../data/eval_os_items_from_db_apr_23_90_days.json', '../data/eval_sentry_items_from_db_apr_23_90_days.json'], \n",
    "    num_entries=3,\n",
    "    shuffle=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab24031ad2f47d3b4666602dda65b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Data:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# save_langsmith(ds_name='small-sentry', filenames=['../data/deleteme_three.json'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repos(filenames):\n",
    "    items = []\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            for i, cur in tqdm(enumerate(data), desc='Validating Data', total=len(data)):\n",
    "                item = EvalItemWithDiff.model_validate(cur)\n",
    "                items.append((item.commit_hash, item.repo_name))\n",
    "    return pd.DataFrame(items, columns=['commit_hash', 'repo_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df28f342ebf490fa6da87bf3126e4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91826d341934da884980ab3da6052ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating Data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_repos_in_ds = get_repos(['../old_data/eval_os_items_from_db_apr_23_90_days.json', '../old_data/eval_sentry_items_from_db_apr_23_90_days.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repos_in_ds.repo_name.value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_repos(['../old_data/eval_os_items_from_db_apr_23_90_days.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
