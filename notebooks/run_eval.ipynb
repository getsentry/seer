{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi==2023.7.22 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer==2.0.12 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: click==8.1.7 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: contourpy==1.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: convertdate==2.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: cycler==0.11.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: Cython==3.0.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: ephem==4.1.4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 8)) (4.1.4)\n",
      "Requirement already satisfied: filelock==3.12.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 9)) (3.12.2)\n",
      "Requirement already satisfied: Flask==2.2.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 10)) (2.2.5)\n",
      "Requirement already satisfied: fonttools==4.42.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 11)) (4.42.1)\n",
      "Requirement already satisfied: fsspec==2023.6.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 12)) (2023.6.0)\n",
      "Requirement already satisfied: gunicorn==20.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 13)) (20.1.0)\n",
      "Requirement already satisfied: holidays==0.31 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 14)) (0.31)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 15)) (3.4)\n",
      "Requirement already satisfied: importlib-resources==6.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 16)) (6.0.1)\n",
      "Requirement already satisfied: itsdangerous==2.1.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 17)) (2.1.2)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 18)) (3.1.2)\n",
      "Requirement already satisfied: joblib==1.3.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 19)) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 20)) (1.4.5)\n",
      "Requirement already satisfied: LunarCalendar==0.0.9 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 21)) (0.0.9)\n",
      "Requirement already satisfied: MarkupSafe==2.1.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 22)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 23)) (3.7.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 24)) (1.3.0)\n",
      "Requirement already satisfied: networkx==3.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 25)) (3.1)\n",
      "Requirement already satisfied: numpy==1.26.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 26)) (1.26.1)\n",
      "Requirement already satisfied: onnx==1.15.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 27)) (1.15.0)\n",
      "Collecting openai==1.6.1 (from -r ../requirements.txt (line 28))\n",
      "  Using cached openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: openai-multi-tool-use-parallel-patch==0.2.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 29)) (0.2.0)\n",
      "Requirement already satisfied: optimum==1.16.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 30)) (1.16.2)\n",
      "Collecting packaging==23.1 (from -r ../requirements.txt (line 31))\n",
      "  Using cached packaging-23.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: pandas==2.0.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 32)) (2.0.3)\n",
      "Requirement already satisfied: patsy==0.5.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 33)) (0.5.3)\n",
      "Requirement already satisfied: Pillow==10.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 34)) (10.0.0)\n",
      "Requirement already satisfied: PyGithub==2.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 35)) (2.1.1)\n",
      "Requirement already satisfied: PyMeeus==0.5.12 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 36)) (0.5.12)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 37)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 38)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2021.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 39)) (2021.3)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 40)) (6.0.1)\n",
      "Requirement already satisfied: regex==2023.8.8 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 41)) (2023.8.8)\n",
      "Requirement already satisfied: requests==2.31.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 42)) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 43)) (1.3.0)\n",
      "Requirement already satisfied: scipy==1.11.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 44)) (1.11.2)\n",
      "Requirement already satisfied: seaborn==0.12.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 45)) (0.12.2)\n",
      "Requirement already satisfied: sentence_transformers==2.3.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 46)) (2.3.1)\n",
      "Requirement already satisfied: sentry-sdk==1.38.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 47)) (1.38.0)\n",
      "Requirement already satisfied: simdkalman==1.0.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 48)) (1.0.2)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 49)) (1.16.0)\n",
      "Requirement already satisfied: statsmodels==0.14.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 50)) (0.14.0)\n",
      "Requirement already satisfied: sympy==1.12 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 51)) (1.12)\n",
      "Requirement already satisfied: threadpoolctl==3.2.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 52)) (3.2.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 53)) (2.0.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 54)) (4.66.1)\n",
      "Requirement already satisfied: typing_extensions==4.7.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 55)) (4.7.1)\n",
      "Requirement already satisfied: tzdata==2023.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 56)) (2023.3)\n",
      "Requirement already satisfied: tree_sitter_languages==1.10.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 57)) (1.10.2)\n",
      "Requirement already satisfied: urllib3==1.26.16 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 58)) (1.26.16)\n",
      "Requirement already satisfied: Werkzeug==2.3.7 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 59)) (2.3.7)\n",
      "Requirement already satisfied: pre-commit==3.5.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 60)) (3.5.0)\n",
      "Requirement already satisfied: black==23.10.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 61)) (23.10.1)\n",
      "Requirement already satisfied: isort==5.12.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 62)) (5.12.0)\n",
      "Requirement already satisfied: flake8==6.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 63)) (6.1.0)\n",
      "Requirement already satisfied: pytest==7.4.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 64)) (7.4.3)\n",
      "Requirement already satisfied: pydantic==2.6.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 65)) (2.6.2)\n",
      "Requirement already satisfied: mypy==1.8.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 66)) (1.8.0)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 67)) (1.0.0)\n",
      "Requirement already satisfied: openapi-core==0.18.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 68)) (0.18.2)\n",
      "Requirement already satisfied: pandas-stubs==2.1.4.231227 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 69)) (2.1.4.231227)\n",
      "Requirement already satisfied: types-Pillow==10.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 70)) (10.1.0.0)\n",
      "Requirement already satisfied: types-colorama==0.4.15.12 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 71)) (0.4.15.12)\n",
      "Requirement already satisfied: types-pywin32==306.0.0.8 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 72)) (306.0.0.8)\n",
      "Requirement already satisfied: types-setuptools==69.0.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 73)) (69.0.0.0)\n",
      "Requirement already satisfied: types-tabulate==0.9.0.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 74)) (0.9.0.3)\n",
      "Requirement already satisfied: types-tqdm==4.66.0.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 75)) (4.66.0.5)\n",
      "Requirement already satisfied: types_pytz==2023.3.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 76)) (2023.3.1.1)\n",
      "Requirement already satisfied: types-openpyxl==3.1.0.32 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 77)) (3.1.0.32)\n",
      "Requirement already satisfied: types-PyYAML==6.0.12.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 78)) (6.0.12.1)\n",
      "Requirement already satisfied: types-jsonschema==4.20.0.20240105 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 79)) (4.20.0.20240105)\n",
      "Requirement already satisfied: types-requests==2.25.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 80)) (2.25.0)\n",
      "Requirement already satisfied: openapi-pydantic==0.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 81)) (0.4.0)\n",
      "Requirement already satisfied: celery==5.3.6 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 82)) (5.3.6)\n",
      "Requirement already satisfied: celery-stubs==0.1.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 83)) (0.1.3)\n",
      "Requirement already satisfied: redis==5.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 84)) (5.0.1)\n",
      "Requirement already satisfied: unidiff==0.7.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 86)) (0.7.5)\n",
      "Requirement already satisfied: transformers==4.37.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 87)) (4.37.2)\n",
      "Requirement already satisfied: psycopg==3.1.18 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 88)) (3.1.18)\n",
      "Requirement already satisfied: pgvector==0.2.4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 89)) (0.2.4)\n",
      "Requirement already satisfied: sqlalchemy==2.0.25 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 90)) (2.0.25)\n",
      "Requirement already satisfied: Flask-Migrate==4.0.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 91)) (4.0.5)\n",
      "Requirement already satisfied: Flask-SQLAlchemy==3.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 92)) (3.1.1)\n",
      "Requirement already satisfied: types-Flask-Migrate==4.0.0.20240205 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 93)) (4.0.0.20240205)\n",
      "Collecting langsmith==0.0.87 (from -r ../requirements.txt (line 94))\n",
      "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pytest-asyncio==0.23.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 95)) (0.23.5)\n",
      "Requirement already satisfied: aiohttp==3.9.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 96)) (3.9.3)\n",
      "Requirement already satisfied: types-python-dateutil==2.8.19.20240106 in /opt/conda/envs/seer/lib/python3.11/site-packages (from -r ../requirements.txt (line 97)) (2.8.19.20240106)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from gunicorn==20.1.0->-r ../requirements.txt (line 13)) (69.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from onnx==1.15.0->-r ../requirements.txt (line 27)) (5.26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai==1.6.1->-r ../requirements.txt (line 28)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai==1.6.1->-r ../requirements.txt (line 28)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai==1.6.1->-r ../requirements.txt (line 28)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai==1.6.1->-r ../requirements.txt (line 28)) (1.3.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/envs/seer/lib/python3.11/site-packages (from optimum==1.16.2->-r ../requirements.txt (line 30)) (15.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from optimum==1.16.2->-r ../requirements.txt (line 30)) (0.21.4)\n",
      "Requirement already satisfied: datasets in /opt/conda/envs/seer/lib/python3.11/site-packages (from optimum==1.16.2->-r ../requirements.txt (line 30)) (2.18.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from PyGithub==2.1.1->-r ../requirements.txt (line 35)) (1.5.0)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub==2.1.1->-r ../requirements.txt (line 35)) (2.8.0)\n",
      "Requirement already satisfied: Deprecated in /opt/conda/envs/seer/lib/python3.11/site-packages (from PyGithub==2.1.1->-r ../requirements.txt (line 35)) (1.2.14)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/seer/lib/python3.11/site-packages (from sentence_transformers==2.3.1->-r ../requirements.txt (line 46)) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/seer/lib/python3.11/site-packages (from sentence_transformers==2.3.1->-r ../requirements.txt (line 46)) (0.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from torch==2.0.1->-r ../requirements.txt (line 53)) (2.0.0)\n",
      "Requirement already satisfied: tree-sitter in /opt/conda/envs/seer/lib/python3.11/site-packages (from tree_sitter_languages==1.10.2->-r ../requirements.txt (line 57)) (0.21.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pre-commit==3.5.0->-r ../requirements.txt (line 60)) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pre-commit==3.5.0->-r ../requirements.txt (line 60)) (2.5.35)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pre-commit==3.5.0->-r ../requirements.txt (line 60)) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pre-commit==3.5.0->-r ../requirements.txt (line 60)) (20.25.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from black==23.10.1->-r ../requirements.txt (line 61)) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from black==23.10.1->-r ../requirements.txt (line 61)) (4.2.0)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from flake8==6.1.0->-r ../requirements.txt (line 63)) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from flake8==6.1.0->-r ../requirements.txt (line 63)) (2.11.1)\n",
      "Requirement already satisfied: pyflakes<3.2.0,>=3.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from flake8==6.1.0->-r ../requirements.txt (line 63)) (3.1.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/envs/seer/lib/python3.11/site-packages (from pytest==7.4.3->-r ../requirements.txt (line 64)) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pytest==7.4.3->-r ../requirements.txt (line 64)) (1.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pydantic==2.6.2->-r ../requirements.txt (line 65)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pydantic==2.6.2->-r ../requirements.txt (line 65)) (2.16.3)\n",
      "Requirement already satisfied: asgiref<4.0.0,>=3.6.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (3.7.2)\n",
      "Requirement already satisfied: isodate in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (4.21.1)\n",
      "Requirement already satisfied: jsonschema-spec<0.3.0,>=0.2.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.2.4)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (10.2.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.7.1)\n",
      "Requirement already satisfied: parse in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-core==0.18.2->-r ../requirements.txt (line 68)) (1.20.1)\n",
      "Requirement already satisfied: referencing in /opt/conda/envs/seer/lib/python3.11/site-packages (from types-jsonschema==4.20.0.20240105->-r ../requirements.txt (line 79)) (0.30.2)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (4.2.0)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (1.1.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (0.3.0)\n",
      "Requirement already satisfied: kombu<6.0,>=5.3.4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (5.3.5)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from celery==5.3.6->-r ../requirements.txt (line 82)) (5.1.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/envs/seer/lib/python3.11/site-packages (from transformers==4.37.2->-r ../requirements.txt (line 87)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from transformers==4.37.2->-r ../requirements.txt (line 87)) (0.4.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/seer/lib/python3.11/site-packages (from sqlalchemy==2.0.25->-r ../requirements.txt (line 90)) (3.0.3)\n",
      "Requirement already satisfied: alembic>=1.9.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from Flask-Migrate==4.0.5->-r ../requirements.txt (line 91)) (1.13.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp==3.9.3->-r ../requirements.txt (line 96)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp==3.9.3->-r ../requirements.txt (line 96)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp==3.9.3->-r ../requirements.txt (line 96)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp==3.9.3->-r ../requirements.txt (line 96)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp==3.9.3->-r ../requirements.txt (line 96)) (1.9.4)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/seer/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r ../requirements.txt (line 53)) (0.42.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/seer/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->-r ../requirements.txt (line 53)) (3.28.3)\n",
      "Requirement already satisfied: lit in /opt/conda/envs/seer/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->-r ../requirements.txt (line 53)) (18.1.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/envs/seer/lib/python3.11/site-packages (from alembic>=1.9.0->Flask-Migrate==4.0.5->-r ../requirements.txt (line 91)) (1.3.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /opt/conda/envs/seer/lib/python3.11/site-packages (from click-repl>=0.2.0->celery==5.3.6->-r ../requirements.txt (line 82)) (3.0.42)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/seer/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.6.1->-r ../requirements.txt (line 28)) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/seer/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.6.1->-r ../requirements.txt (line 28)) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/seer/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.18.0)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.4.3)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from kombu<6.0,>=5.3.4->celery==5.3.6->-r ../requirements.txt (line 82)) (5.2.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.1.4)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (0.3.2)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core==0.18.2->-r ../requirements.txt (line 68)) (1.10.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pyjwt[crypto]>=2.4.0->PyGithub==2.1.1->-r ../requirements.txt (line 35)) (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pynacl>=1.4.0->PyGithub==2.1.1->-r ../requirements.txt (line 35)) (1.16.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/envs/seer/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit==3.5.0->-r ../requirements.txt (line 60)) (0.3.8)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from coloredlogs->optimum==1.16.2->-r ../requirements.txt (line 30)) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from datasets->optimum==1.16.2->-r ../requirements.txt (line 30)) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/envs/seer/lib/python3.11/site-packages (from datasets->optimum==1.16.2->-r ../requirements.txt (line 30)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from datasets->optimum==1.16.2->-r ../requirements.txt (line 30)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/seer/lib/python3.11/site-packages (from datasets->optimum==1.16.2->-r ../requirements.txt (line 30)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/seer/lib/python3.11/site-packages (from datasets->optimum==1.16.2->-r ../requirements.txt (line 30)) (0.70.16)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/envs/seer/lib/python3.11/site-packages (from Deprecated->PyGithub==2.1.1->-r ../requirements.txt (line 35)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/seer/lib/python3.11/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub==2.1.1->-r ../requirements.txt (line 35)) (2.21)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/seer/lib/python3.11/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery==5.3.6->-r ../requirements.txt (line 82)) (0.2.13)\n",
      "Using cached openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: packaging, openai, langsmith\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.14.1\n",
      "    Uninstalling openai-1.14.1:\n",
      "      Successfully uninstalled openai-1.14.1\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.27\n",
      "    Uninstalling langsmith-0.1.27:\n",
      "      Successfully uninstalled langsmith-0.1.27\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.1.32 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.87 which is incompatible.\n",
      "langchain-core 0.1.32 requires packaging<24.0,>=23.2, but you have packaging 23.1 which is incompatible.\n",
      "langchain 0.1.12 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.0.87 which is incompatible.\n",
      "langchain-openai 0.0.8 requires openai<2.0.0,>=1.10.0, but you have openai 1.6.1 which is incompatible.\n",
      "langchain-community 0.0.28 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.87 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langsmith-0.0.87 openai-1.6.1 packaging-23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple more libraries are needed for running the eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/seer/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in /opt/conda/envs/seer/lib/python3.11/site-packages (0.1.12)\n",
      "Requirement already satisfied: langchain-openai in /opt/conda/envs/seer/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: psycopg[binary,pool] in /opt/conda/envs/seer/lib/python3.11/site-packages (3.1.18)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from psycopg[binary,pool]) (4.7.1)\n",
      "Requirement already satisfied: psycopg-binary==3.1.18 in /opt/conda/envs/seer/lib/python3.11/site-packages (from psycopg[binary,pool]) (3.1.18)\n",
      "Requirement already satisfied: psycopg-pool in /opt/conda/envs/seer/lib/python3.11/site-packages (from psycopg[binary,pool]) (3.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (0.1.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.27-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (2.6.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
      "  Using cached openai-1.14.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/seer/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.3.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.31->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/seer/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/envs/seer/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/envs/seer/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/seer/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/seer/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/seer/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/seer/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/seer/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/envs/seer/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.8.8)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/seer/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/seer/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/seer/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached langsmith-0.1.27-py3-none-any.whl (68 kB)\n",
      "Using cached openai-1.14.1-py3-none-any.whl (257 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging, openai, langsmith\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.6.1\n",
      "    Uninstalling openai-1.6.1:\n",
      "      Successfully uninstalled openai-1.6.1\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.87\n",
      "    Uninstalling langsmith-0.0.87:\n",
      "      Successfully uninstalled langsmith-0.0.87\n",
      "Successfully installed langsmith-0.1.27 openai-1.14.1 packaging-23.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv 'psycopg[binary,pool]' langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/seer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Flask '__main__'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['DATABASE_URL'] = \"postgresql+psycopg://root:seer@localhost:5433/seer\"\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"ai-autofix-evals\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('autofix')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "from github import Github\n",
    "from github.Auth import Token\n",
    "\n",
    "github = Github(auth=Token(token=os.environ.get('GITHUB_TOKEN')))\n",
    "repo = github.get_repo('getsentry/sentry')\n",
    "\n",
    "from seer.bootup import bootup\n",
    "\n",
    "bootup(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import field_serializer, BaseModel\n",
    "from github.Commit import Commit\n",
    "from typing import Any\n",
    "from pydantic import ConfigDict, field_validator\n",
    "\n",
    "from seer.automation.autofix.models import IssueDetails, EventDetails\n",
    "\n",
    "class EvalItem(BaseModel):\n",
    "    raw_data: dict[str, Any]\n",
    "    commit: Commit\n",
    "    issue: IssueDetails\n",
    "    event: EventDetails\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True\n",
    "    )\n",
    "\n",
    "    @field_serializer('commit')\n",
    "    def serialize_commit(self, commit: Commit, _info):\n",
    "        return commit.sha\n",
    "    \n",
    "    @field_validator('commit', mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_commit(cls, commit: Commit | str):\n",
    "        return commit if isinstance(commit, Commit) else repo.get_commit(commit)\n",
    "    \n",
    "class EvalItemWithDiff(EvalItem):\n",
    "    diff: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the eval items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36 eval items\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "eval_file = '../data/full_eval_autofix_240314.json'\n",
    "\n",
    "with open(eval_file, 'r') as file:\n",
    "    tmp_autofix_data = json.load(file)\n",
    "\n",
    "eval_data = [EvalItemWithDiff.model_validate(item) for item in tmp_autofix_data]\n",
    "\n",
    "print(f\"Loaded {len(eval_data)} eval items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Autofix pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded codebase index for getsentry/sentry, with existing data\n"
     ]
    }
   ],
   "source": [
    "from seer.automation.autofix.autofix import Autofix\n",
    "from seer.automation.autofix.tasks import ContinuationState\n",
    "from seer.rpc import DummyRpcClient\n",
    "from seer.automation.autofix.models import (\n",
    "    AutofixContinuation,\n",
    "    AutofixRequest,\n",
    "    IssueDetails,\n",
    "    RepoDefinition,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from seer.automation.autofix.autofix_context import AutofixContext\n",
    "from seer.automation.autofix.event_manager import AutofixEventManager\n",
    "\n",
    "# Initializes the rpc client in DRY RUN mode\n",
    "rpc_client = DummyRpcClient()\n",
    "rpc_client.dry_run = True\n",
    "\n",
    "request = AutofixRequest(\n",
    "    organization_id=1,\n",
    "    project_id=1,\n",
    "    repos=[RepoDefinition(provider=\"github\", owner=\"getsentry\", name=\"sentry\")],\n",
    "    base_commit_sha=eval_data[0].commit.parents[0].sha,\n",
    "    issue=eval_data[0].issue,\n",
    ")\n",
    "\n",
    "state = ContinuationState(\n",
    "    val=AutofixContinuation(request=AutofixRequest.model_validate(request)), rpc_client=rpc_client\n",
    ")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"../models/autofix_embeddings_v0\", trust_remote_code=True)\n",
    "embedding_model.max_seq_length = 4096\n",
    "\n",
    "event_manager = AutofixEventManager(state)\n",
    "context = AutofixContext(\n",
    "    organization_id=request.organization_id,\n",
    "    project_id=request.project_id,\n",
    "    repos=request.repos,\n",
    "    event_manager=event_manager,\n",
    "    state=state,\n",
    "    embedding_model=embedding_model,\n",
    ")\n",
    "context.commit_changes = False\n",
    "autofix = Autofix(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning autofix for issue 5059849041\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "Updating codebase index for repo getsentry/sentry to d20e05ec5350501560e8e06f4aa9e4b445b286dd\n",
      "on_autofix_step_update invoking...\n",
      "on_autofix_step_update done\n",
      "Updating codebase index with 386 changed files and 24 removed files...\n",
      "Loading repository to /var/tmp/getsentry-sentry_d20e05ec5350501560e8e06f4aa9e4b445b286dd3pv8ez6w/repo\n",
      "Loaded repository to /var/tmp/getsentry-sentry_d20e05ec5350501560e8e06f4aa9e4b445b286dd3pv8ez6w/repo\n",
      "File not found: /var/tmp/getsentry-sentry_d20e05ec5350501560e8e06f4aa9e4b445b286dd3pv8ez6w/repo/static/app/components/events/autofix/autofixInstructionsModal.tsx\n",
      "/opt/conda/envs/seer/lib/python3.11/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 1/376\n",
      "Document chunking took 0.60 seconds\n",
      "Processed document 2/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 3/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 4/376\n",
      "Document chunking took 0.41 seconds\n",
      "Processed document 5/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 6/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 7/376\n",
      "Document chunking took 0.32 seconds\n",
      "Processed document 8/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 9/376\n",
      "Document chunking took 0.41 seconds\n",
      "Processed document 10/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 11/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 12/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 13/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 14/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 15/376\n",
      "Document chunking took 1.18 seconds\n",
      "Processed document 16/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 17/376\n",
      "Document chunking took 0.30 seconds\n",
      "Processed document 18/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 19/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 20/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 21/376\n",
      "Document chunking took 0.18 seconds\n",
      "Processed document 22/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 23/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 24/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 25/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 26/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 27/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 28/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 29/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 30/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 31/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 32/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 33/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 34/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 35/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 36/376\n",
      "Document chunking took 0.48 seconds\n",
      "Processed document 37/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 38/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 39/376\n",
      "Document chunking took 0.14 seconds\n",
      "Processed document 40/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 41/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 42/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 43/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 44/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 45/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 46/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 47/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 48/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 49/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 50/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 51/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 52/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 53/376\n",
      "Document chunking took 0.23 seconds\n",
      "Processed document 54/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 55/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 56/376\n",
      "Document chunking took 0.31 seconds\n",
      "Processed document 57/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 58/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 59/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 60/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 61/376\n",
      "Document chunking took 0.73 seconds\n",
      "Processed document 62/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 63/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 64/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 65/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 66/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 67/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 68/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 69/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 70/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 71/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 72/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 73/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 74/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 75/376\n",
      "Document chunking took 0.53 seconds\n",
      "Processed document 76/376\n",
      "Document chunking took 0.11 seconds\n",
      "Processed document 77/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 78/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 79/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 80/376\n",
      "Document chunking took 0.14 seconds\n",
      "Processed document 81/376\n",
      "Document chunking took 0.21 seconds\n",
      "Processed document 82/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 83/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 84/376\n",
      "Document chunking took 0.20 seconds\n",
      "Processed document 85/376\n",
      "Document chunking took 0.21 seconds\n",
      "Processed document 86/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 87/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 88/376\n",
      "Document chunking took 0.20 seconds\n",
      "Processed document 89/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 90/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 91/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 92/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 93/376\n",
      "Document chunking took 0.17 seconds\n",
      "Processed document 94/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 95/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 96/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 97/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 98/376\n",
      "Document chunking took 0.11 seconds\n",
      "Processed document 99/376\n",
      "Document chunking took 0.44 seconds\n",
      "Processed document 100/376\n",
      "Document chunking took 0.23 seconds\n",
      "Processed document 101/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 102/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 103/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 104/376\n",
      "Document chunking took 0.28 seconds\n",
      "Processed document 105/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 106/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 107/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 108/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 109/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 110/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 111/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 112/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 113/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 114/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 115/376\n",
      "Document chunking took 0.49 seconds\n",
      "Processed document 116/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 117/376\n",
      "Document chunking took 0.59 seconds\n",
      "Processed document 118/376\n",
      "Document chunking took 0.27 seconds\n",
      "Processed document 119/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 120/376\n",
      "Document chunking took 0.26 seconds\n",
      "Processed document 121/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 122/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 123/376\n",
      "Document chunking took 1.22 seconds\n",
      "Processed document 124/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 125/376\n",
      "Document chunking took 0.37 seconds\n",
      "Processed document 126/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 127/376\n",
      "Document chunking took 1.93 seconds\n",
      "Processed document 128/376\n",
      "Document chunking took 0.14 seconds\n",
      "Processed document 129/376\n",
      "Document chunking took 0.27 seconds\n",
      "Processed document 130/376\n",
      "Document chunking took 0.15 seconds\n",
      "Processed document 131/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 132/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 133/376\n",
      "Document chunking took 0.18 seconds\n",
      "Processed document 134/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 135/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 136/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 137/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 138/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 139/376\n",
      "Document chunking took 0.15 seconds\n",
      "Processed document 140/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 141/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 142/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 143/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 144/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 145/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 146/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 147/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 148/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 149/376\n",
      "Document chunking took 0.35 seconds\n",
      "Processed document 150/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 151/376\n",
      "Document chunking took 0.22 seconds\n",
      "Processed document 152/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 153/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 154/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 155/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 156/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 157/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 158/376\n",
      "Document chunking took 0.14 seconds\n",
      "Processed document 159/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 160/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 161/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 162/376\n",
      "Document chunking took 0.25 seconds\n",
      "Processed document 163/376\n",
      "Document chunking took 0.24 seconds\n",
      "Processed document 164/376\n",
      "Document chunking took 0.25 seconds\n",
      "Processed document 165/376\n",
      "Document chunking took 0.21 seconds\n",
      "Processed document 166/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 167/376\n",
      "Document chunking took 0.23 seconds\n",
      "Processed document 168/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 169/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 170/376\n",
      "Document chunking took 0.44 seconds\n",
      "Processed document 171/376\n",
      "Document chunking took 0.77 seconds\n",
      "Processed document 172/376\n",
      "Document chunking took 0.37 seconds\n",
      "Processed document 173/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 174/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 175/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 176/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 177/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 178/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 179/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 180/376\n",
      "Document chunking took 0.63 seconds\n",
      "Processed document 181/376\n",
      "Document chunking took 0.18 seconds\n",
      "Processed document 182/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 183/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 184/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 185/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 186/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 187/376\n",
      "Document chunking took 0.15 seconds\n",
      "Processed document 188/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 189/376\n",
      "Document chunking took 0.22 seconds\n",
      "Processed document 190/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 191/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 192/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 193/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 194/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 195/376\n",
      "Document chunking took 0.19 seconds\n",
      "Processed document 196/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 197/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 198/376\n",
      "Document chunking took 0.26 seconds\n",
      "Processed document 199/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 200/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 201/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 202/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 203/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 204/376\n",
      "Document chunking took 0.28 seconds\n",
      "Processed document 205/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 206/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 207/376\n",
      "Document chunking took 0.37 seconds\n",
      "Processed document 208/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 209/376\n",
      "Document chunking took 0.67 seconds\n",
      "Processed document 210/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 211/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 212/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 213/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 214/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 215/376\n",
      "Document chunking took 0.32 seconds\n",
      "Processed document 216/376\n",
      "Document chunking took 1.70 seconds\n",
      "Processed document 217/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 218/376\n",
      "Document chunking took 0.33 seconds\n",
      "Processed document 219/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 220/376\n",
      "Document chunking took 0.20 seconds\n",
      "Processed document 221/376\n",
      "Document chunking took 0.33 seconds\n",
      "Processed document 222/376\n",
      "Document chunking took 0.17 seconds\n",
      "Processed document 223/376\n",
      "Document chunking took 0.40 seconds\n",
      "Processed document 224/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 225/376\n",
      "Document chunking took 0.26 seconds\n",
      "Processed document 226/376\n",
      "Document chunking took 0.14 seconds\n",
      "Processed document 227/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 228/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 229/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 230/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 231/376\n",
      "Document chunking took 1.08 seconds\n",
      "Processed document 232/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 233/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 234/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 235/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 236/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 237/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 238/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 239/376\n",
      "Document chunking took 0.53 seconds\n",
      "Processed document 240/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 241/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 242/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 243/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 244/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 245/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 246/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 247/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 248/376\n",
      "Document chunking took 0.25 seconds\n",
      "Processed document 249/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 250/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 251/376\n",
      "Document chunking took 0.25 seconds\n",
      "Processed document 252/376\n",
      "Document chunking took 0.76 seconds\n",
      "Processed document 253/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 254/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 255/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 256/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 257/376\n",
      "Document chunking took 0.23 seconds\n",
      "Processed document 258/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 259/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 260/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 261/376\n",
      "Document chunking took 0.23 seconds\n",
      "Processed document 262/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 263/376\n",
      "Document chunking took 0.35 seconds\n",
      "Processed document 264/376\n",
      "Document chunking took 0.20 seconds\n",
      "Processed document 265/376\n",
      "Document chunking took 0.32 seconds\n",
      "Processed document 266/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 267/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 268/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 269/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 270/376\n",
      "Document chunking took 0.59 seconds\n",
      "Processed document 271/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 272/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 273/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 274/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 275/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 276/376\n",
      "Document chunking took 0.17 seconds\n",
      "Processed document 277/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 278/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 279/376\n",
      "Document chunking took 0.27 seconds\n",
      "Processed document 280/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 281/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 282/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 283/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 284/376\n",
      "Document chunking took 0.26 seconds\n",
      "Processed document 285/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 286/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 287/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 288/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 289/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 290/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 291/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 292/376\n",
      "Document chunking took 0.24 seconds\n",
      "Processed document 293/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 294/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 295/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 296/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 297/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 298/376\n",
      "Document chunking took 0.15 seconds\n",
      "Processed document 299/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 300/376\n",
      "Document chunking took 0.13 seconds\n",
      "Processed document 301/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 302/376\n",
      "Document chunking took 0.10 seconds\n",
      "Processed document 303/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 304/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 305/376\n",
      "Document chunking took 0.09 seconds\n",
      "Processed document 306/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 307/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 308/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 309/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 310/376\n",
      "Document chunking took 0.39 seconds\n",
      "Processed document 311/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 312/376\n",
      "Document chunking took 0.20 seconds\n",
      "Processed document 313/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 314/376\n",
      "Document chunking took 0.30 seconds\n",
      "Processed document 315/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 316/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 317/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 318/376\n",
      "Document chunking took 1.09 seconds\n",
      "Processed document 319/376\n",
      "Document chunking took 0.42 seconds\n",
      "Processed document 320/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 321/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 322/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 323/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 324/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 325/376\n",
      "Document chunking took 0.44 seconds\n",
      "Processed document 326/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 327/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 328/376\n",
      "Document chunking took 0.40 seconds\n",
      "Processed document 329/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 330/376\n",
      "Document chunking took 0.17 seconds\n",
      "Processed document 331/376\n",
      "Document chunking took 0.18 seconds\n",
      "Processed document 332/376\n",
      "Document chunking took 0.34 seconds\n",
      "Processed document 333/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 334/376\n",
      "Document chunking took 0.07 seconds\n",
      "Processed document 335/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 336/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 337/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 338/376\n",
      "Document chunking took 0.22 seconds\n",
      "Processed document 339/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 340/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 341/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 342/376\n",
      "Document chunking took 0.47 seconds\n",
      "Processed document 343/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 344/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 345/376\n",
      "Document chunking took 0.26 seconds\n",
      "Processed document 346/376\n",
      "Document chunking took 0.06 seconds\n",
      "Processed document 347/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 348/376\n",
      "Document chunking took 0.04 seconds\n",
      "Processed document 349/376\n",
      "Document chunking took 0.00 seconds\n",
      "Processed document 350/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 351/376\n",
      "Document chunking took 0.01 seconds\n",
      "Processed document 352/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 353/376\n",
      "Document chunking took 0.02 seconds\n",
      "Processed document 354/376\n",
      "Document chunking took 0.12 seconds\n",
      "Processed document 355/376\n",
      "Document chunking took 0.24 seconds\n",
      "Processed document 356/376\n",
      "Document chunking took 0.37 seconds\n",
      "Processed document 357/376\n",
      "Document chunking took 0.03 seconds\n",
      "Processed document 358/376\n",
      "Document chunking took 0.15 seconds\n",
      "Processed document 359/376\n",
      "Document chunking took 0.05 seconds\n",
      "Processed document 360/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 361/376\n",
      "Document chunking took 0.08 seconds\n",
      "Processed document 362/376\n",
      "Document chunking took 0.16 seconds\n",
      "Processed document 363/376\n"
     ]
    }
   ],
   "source": [
    "# Runs the autofix run\n",
    "autofix_result = autofix.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f5dfe6b63a74039ec81614f9f07e2814ffa45dad'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.get_codebase(1).working_sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting file contents for tests/sentry/issues/test_issue_velocity.py in getsentry/sentry on sha f5dfe6b63a74039ec81614f9f07e2814ffa45dad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import math\n",
      "from datetime import datetime, timedelta\n",
      "from unittest.mock import patch\n",
      "\n",
      "from django.utils import timezone\n",
      "\n",
      "from sentry.issues.issue_velocity import (\n",
      "    DEFAULT_TTL,\n",
      "    FALLBACK_TTL,\n",
      "    STALE_DATE_KEY,\n",
      "    THRESHOLD_KEY,\n",
      "    TIME_TO_USE_EXISTING_THRESHOLD,\n",
      "    calculate_threshold,\n",
      "    fallback_to_stale_or_zero,\n",
      "    get_latest_threshold,\n",
      "    get_redis_client,\n",
      "    update_threshold,\n",
      ")\n",
      "from sentry.tasks.post_process import locks\n",
      "from sentry.testutils.cases import SnubaTestCase, TestCase\n",
      "from sentry.testutils.helpers.datetime import freeze_time, iso_format\n",
      "from sentry.testutils.silo import region_silo_test\n",
      "\n",
      "WEEK_IN_HOURS = 7 * 24\n",
      "\n",
      "\n",
      "@region_silo_test\n",
      "@freeze_time()\n",
      "class IssueVelocityTests(TestCase, SnubaTestCase):\n",
      "    def setUp(self):\n",
      "        self.now = timezone.now()\n",
      "        self.utcnow = datetime.utcnow()\n",
      "        super().setUp()\n",
      "\n",
      "    def test_calculation_simple(self):\n",
      "        \"\"\"\n",
      "        Tests threshold calculation for a single issue with the minimum number of events\n",
      "        in the past week.\n",
      "        \"\"\"\n",
      "        self.store_event(\n",
      "            project_id=self.project.id,\n",
      "            data={\n",
      "                \"fingerprint\": [\"group-1\"],\n",
      "                \"timestamp\": iso_format(self.now - timedelta(days=8)),\n",
      "                \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "            },\n",
      "        )\n",
      "        for _ in range(2):\n",
      "            self.store_event(\n",
      "                project_id=self.project.id,\n",
      "                data={\n",
      "                    \"fingerprint\": [\"group-1\"],\n",
      "                    \"timestamp\": iso_format(self.now - timedelta(days=1)),\n",
      "                    \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "                },\n",
      "            )\n",
      "\n",
      "        threshold = calculate_threshold(self.project)\n",
      "        assert threshold == 2 / WEEK_IN_HOURS\n",
      "\n",
      "    def test_calculation_multiple_issues(self):\n",
      "        \"\"\"\n",
      "        Tests that we receive the approximate 90th percentile for multiple issues older than a week\n",
      "        with multiple events in the past week.\n",
      "        \"\"\"\n",
      "        for i in range(5):\n",
      "            # ensure the velocity for each issue is calculated using the whole week\n",
      "            self.store_event(\n",
      "                project_id=self.project.id,\n",
      "                data={\n",
      "                    \"fingerprint\": [f\"group-{i}\"],\n",
      "                    \"timestamp\": iso_format(self.now - timedelta(days=8)),\n",
      "                    \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "                },\n",
      "            )\n",
      "            for _ in range(i + 2):\n",
      "                # fill with events that happened in the previous week\n",
      "                self.store_event(\n",
      "                    project_id=self.project.id,\n",
      "                    data={\n",
      "                        \"fingerprint\": [f\"group-{i}\"],\n",
      "                        \"timestamp\": iso_format(self.now - timedelta(days=1)),\n",
      "                        \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "                    },\n",
      "                )\n",
      "\n",
      "        # approximate calculation of 95th percentile for small sample\n",
      "        expected_threshold = 6 * 0.95 / WEEK_IN_HOURS\n",
      "        actual_threshold = calculate_threshold(self.project)\n",
      "\n",
      "        # clickhouse's quantile function is approximate\n",
      "        # https://clickhouse.com/docs/en/sql-reference/aggregate-functions/reference/quantile\n",
      "        assert actual_threshold is not None\n",
      "        assert math.isclose(expected_threshold, actual_threshold, abs_tol=10**-3)\n",
      "\n",
      "    def test_calculation_for_issues_first_seen_recently(self):\n",
      "        \"\"\"\n",
      "        Tests that issues first seen within the past week use the difference in hours between now\n",
      "        and when they were first seen to calculate frequency instead of the full week in hours.\n",
      "        \"\"\"\n",
      "        for _ in range(2):\n",
      "            self.store_event(\n",
      "                project_id=self.project.id,\n",
      "                data={\n",
      "                    \"fingerprint\": [\"group-1\"],\n",
      "                    \"timestamp\": iso_format(self.now - timedelta(days=1)),\n",
      "                    \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "                },\n",
      "            )\n",
      "        threshold = calculate_threshold(self.project)\n",
      "        assert threshold == 2 / 24\n",
      "\n",
      "    def test_calculation_excludes_issues_with_only_one_event_in_past_week(self):\n",
      "        \"\"\"\n",
      "        Tests that issues with only one event in the past week are excluded from the calculation.\n",
      "        \"\"\"\n",
      "        self.store_event(\n",
      "            project_id=self.project.id,\n",
      "            data={\n",
      "                \"fingerprint\": [\"group-1\"],\n",
      "                \"timestamp\": iso_format(self.now - timedelta(days=8)),\n",
      "                \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "            },\n",
      "        )\n",
      "\n",
      "        self.store_event(\n",
      "            project_id=self.project.id,\n",
      "            data={\n",
      "                \"fingerprint\": [\"group-1\"],\n",
      "                \"timestamp\": iso_format(self.now - timedelta(days=1)),\n",
      "                \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "            },\n",
      "        )\n",
      "\n",
      "        threshold = calculate_threshold(self.project)\n",
      "        assert threshold is not None\n",
      "        assert math.isnan(threshold)\n",
      "\n",
      "    def test_calculation_excludes_issues_newer_than_an_hour(self):\n",
      "        \"\"\"\n",
      "        Tests that issues that were first seen within the past hour are excluded from the calculation.\n",
      "        \"\"\"\n",
      "        self.store_event(\n",
      "            project_id=self.project.id,\n",
      "            data={\n",
      "                \"fingerprint\": [\"group-1\"],\n",
      "                \"timestamp\": iso_format(self.now - timedelta(minutes=1)),\n",
      "                \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "            },\n",
      "        )\n",
      "\n",
      "        self.store_event(\n",
      "            project_id=self.project.id,\n",
      "            data={\n",
      "                \"fingerprint\": [\"group-1\"],\n",
      "                \"timestamp\": iso_format(self.now - timedelta(minutes=1)),\n",
      "                \"user\": {\"id\": self.user.id, \"email\": self.user.email},\n",
      "            },\n",
      "        )\n",
      "\n",
      "        threshold = calculate_threshold(self.project)\n",
      "        assert threshold is not None\n",
      "        assert math.isnan(threshold)\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.update_threshold\")\n",
      "    def test_get_latest_threshold_simple(self, mock_update):\n",
      "        \"\"\"\n",
      "        Tests that we get the last threshold stored when the stale date has not passed yet.\n",
      "        \"\"\"\n",
      "        redis_client = get_redis_client()\n",
      "        redis_client.set(THRESHOLD_KEY.format(project_id=self.project.id), 0.1)\n",
      "        redis_client.set(STALE_DATE_KEY.format(project_id=self.project.id), str(self.utcnow))\n",
      "        threshold = get_latest_threshold(self.project)\n",
      "        mock_update.assert_not_called()\n",
      "        assert threshold == 0.1\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.update_threshold\")\n",
      "    def test_get_latest_threshold_outdated(self, mock_update):\n",
      "        \"\"\"\n",
      "        Tests that we update the threshold when the stale date has passed.\n",
      "        \"\"\"\n",
      "        redis_client = get_redis_client()\n",
      "        redis_client.set(THRESHOLD_KEY.format(project_id=self.project.id), 1.2)\n",
      "        redis_client.set(\n",
      "            STALE_DATE_KEY.format(project_id=self.project.id),\n",
      "            str(self.utcnow - timedelta(days=1, seconds=1)),\n",
      "        )\n",
      "        mock_update.return_value = 1.5\n",
      "        assert get_latest_threshold(self.project) == 1.5\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.update_threshold\")\n",
      "    def test_get_latest_threshold_when_none_saved(self, mock_update):\n",
      "        \"\"\"\n",
      "        Tests that we update the threshold when it is non-existent.\n",
      "        \"\"\"\n",
      "        mock_update.return_value = 10.7\n",
      "        assert get_latest_threshold(self.project) == 10.7\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.update_threshold\")\n",
      "    def test_get_latest_threshold_locked(self, mock_update):\n",
      "        \"\"\"\n",
      "        Tests that we return the stale threshold when another process has the lock.\n",
      "        \"\"\"\n",
      "        redis_client = get_redis_client()\n",
      "        redis_client.set(THRESHOLD_KEY.format(project_id=self.project.id), 0.7)\n",
      "        redis_client.set(\n",
      "            STALE_DATE_KEY.format(project_id=self.project.id),\n",
      "            str(self.utcnow - timedelta(days=1)),\n",
      "        )\n",
      "\n",
      "        lock = locks.get(\n",
      "            f\"calculate_project_thresholds:{self.project.id}\",\n",
      "            duration=10,\n",
      "            name=\"calculate_project_thresholds\",\n",
      "        )\n",
      "        with lock.acquire():\n",
      "            threshold = get_latest_threshold(self.project)\n",
      "            mock_update.assert_not_called()\n",
      "            assert threshold == 0.7\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.update_threshold\")\n",
      "    def test_get_latest_threshold_locked_no_stale(self, mock_update):\n",
      "        \"\"\"\n",
      "        Tests that we return 0 when another process has the lock and there is no stale value.\n",
      "        \"\"\"\n",
      "        lock = locks.get(\n",
      "            f\"calculate_project_thresholds:{self.project.id}\",\n",
      "            duration=10,\n",
      "            name=\"calculate_project_thresholds\",\n",
      "        )\n",
      "        with lock.acquire():\n",
      "            threshold = get_latest_threshold(self.project)\n",
      "            mock_update.assert_not_called()\n",
      "            assert threshold == 0\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.calculate_threshold\")\n",
      "    def test_update_threshold_simple(self, mock_calculation):\n",
      "        \"\"\"\n",
      "        Tests that we save the newly calculated threshold at the default TTL and return it.\n",
      "        \"\"\"\n",
      "        mock_calculation.return_value = 5\n",
      "        threshold = update_threshold(self.project.id, \"threshold-key\", \"date-key\")\n",
      "        assert threshold == 5\n",
      "        redis_client = get_redis_client()\n",
      "        assert redis_client.get(\"threshold-key\") == \"5\"\n",
      "        stored_date = redis_client.get(\"date-key\")\n",
      "        assert isinstance(stored_date, str)\n",
      "        assert datetime.fromisoformat(stored_date) == self.utcnow\n",
      "        assert redis_client.ttl(\"threshold-key\") == DEFAULT_TTL\n",
      "        assert redis_client.ttl(\"date-key\") == DEFAULT_TTL\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.calculate_threshold\")\n",
      "    def test_update_threshold_with_stale(self, mock_calculation):\n",
      "        \"\"\"\n",
      "        Tests that we return the stale threshold if the calculation method returns None.\n",
      "        \"\"\"\n",
      "        mock_calculation.return_value = None\n",
      "        redis_client = get_redis_client()\n",
      "        redis_client.set(\"threshold-key\", 0.5, ex=86400)\n",
      "\n",
      "        assert update_threshold(self.project, \"threshold-key\", \"date-key\", 0.5) == 0.5\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.calculate_threshold\")\n",
      "    def test_update_threshold_none(self, mock_calculation):\n",
      "        \"\"\"\n",
      "        Tests that we return 0 if the calculation method returns None and we don't have a stale\n",
      "        threshold.\n",
      "        \"\"\"\n",
      "        mock_calculation.return_value = None\n",
      "        assert update_threshold(self.project, \"threshold-key\", \"date-key\") == 0\n",
      "\n",
      "    @patch(\"sentry.issues.issue_velocity.calculate_threshold\")\n",
      "    def test_update_threshold_nan(self, mock_calculation):\n",
      "        \"\"\"\n",
      "        Tests that we return 0 and save a threshold for the default TTL if the calculation returned NaN.\n",
      "        \"\"\"\n",
      "        mock_calculation.return_value = float(\"nan\")\n",
      "        assert update_threshold(self.project, \"threshold-key\", \"date-key\") == 0\n",
      "        redis_client = get_redis_client()\n",
      "        assert redis_client.get(\"threshold-key\") == \"0\"\n",
      "        stored_date = redis_client.get(\"date-key\")\n",
      "        assert isinstance(stored_date, str)\n",
      "        assert datetime.fromisoformat(stored_date) == self.utcnow\n",
      "        assert redis_client.ttl(\"threshold-key\") == DEFAULT_TTL\n",
      "\n",
      "    def test_fallback_to_stale(self):\n",
      "        \"\"\"\n",
      "        Tests that we return the stale threshold and maintain its TTL, and update the stale date to\n",
      "        make the threshold usable for the next ten minutes as a fallback.\n",
      "        \"\"\"\n",
      "        redis_client = get_redis_client()\n",
      "        redis_client.set(\"threshold-key\", 0.5, ex=86400)\n",
      "\n",
      "        assert fallback_to_stale_or_zero(\"threshold-key\", \"date-key\", 0.5) == 0.5\n",
      "        assert redis_client.get(\"threshold-key\") == \"0.5\"\n",
      "        stored_date = redis_client.get(\"date-key\")\n",
      "        assert isinstance(stored_date, str)\n",
      "        assert datetime.fromisoformat(stored_date) == (\n",
      "            self.utcnow\n",
      "            - timedelta(seconds=TIME_TO_USE_EXISTING_THRESHOLD)\n",
      "            + timedelta(seconds=FALLBACK_TTL)\n",
      "        )\n",
      "\n",
      "        assert redis_client.ttl(\"threshold-key\") == 86400\n",
      "        assert redis_client.ttl(\"date-key\") == 86400\n",
      "\n",
      "    def test_fallback_to_zero(self):\n",
      "        \"\"\"\n",
      "        Tests that we return 0 and store it in Redis for the next ten minutes as a fallback if we\n",
      "        do not have a stale threshold.\n",
      "        \"\"\"\n",
      "        assert fallback_to_stale_or_zero(\"threshold-key\", \"date-key\", None) == 0\n",
      "        redis_client = get_redis_client()\n",
      "        assert redis_client.get(\"threshold-key\") == \"0\"\n",
      "        stored_date = redis_client.get(\"date-key\")\n",
      "        assert isinstance(stored_date, str)\n",
      "        assert datetime.fromisoformat(stored_date) == (\n",
      "            self.utcnow\n",
      "            - timedelta(seconds=TIME_TO_USE_EXISTING_THRESHOLD)\n",
      "            + timedelta(seconds=FALLBACK_TTL)\n",
      "        )\n",
      "        assert redis_client.ttl(\"threshold-key\") == FALLBACK_TTL\n",
      "        assert redis_client.ttl(\"date-key\") == FALLBACK_TTL\n",
      "\n",
      "    def test_fallback_to_stale_zero_ttl(self):\n",
      "        \"\"\"\n",
      "        Tests that we return 0 and store it in Redis for the next ten minutes as a fallback if our\n",
      "        stale threshold has a TTL <= 0.\n",
      "        \"\"\"\n",
      "        redis_client = get_redis_client()\n",
      "        assert fallback_to_stale_or_zero(\"threshold-key\", \"date-key\", 0.5) == 0\n",
      "        assert redis_client.get(\"threshold-key\") == \"0\"\n",
      "        stored_date = redis_client.get(\"date-key\")\n",
      "        assert isinstance(stored_date, str)\n",
      "        assert datetime.fromisoformat(stored_date) == (\n",
      "            self.utcnow\n",
      "            - timedelta(seconds=TIME_TO_USE_EXISTING_THRESHOLD)\n",
      "            + timedelta(seconds=FALLBACK_TTL)\n",
      "        )\n",
      "\n",
      "        assert redis_client.ttl(\"threshold-key\") == FALLBACK_TTL\n",
      "        assert redis_client.ttl(\"date-key\") == FALLBACK_TTL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context.get_codebase(1).repo_client.get_file_content('tests/sentry/issues/test_issue_velocity.py', sha='f5dfe6b63a74039ec81614f9f07e2814ffa45dad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP scoring the diffs\n",
    "\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from github.Commit import Commit\n",
    "from github.File import File\n",
    "\n",
    "from seer.automation.autofix.models import AutofixOutput\n",
    "from seer.automation.autofix.prompts import format_exceptions\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4-0125-preview\")\n",
    "\n",
    "item = eval_data[0]\n",
    "\n",
    "def score_fix(eval_item: EvalItemWithDiff, predicted_output: AutofixOutput):\n",
    "    model.invoke(f\"\"\"<issue>\n",
    "<error_message>\n",
    "{eval_item.event.title}\n",
    "</error_message>\n",
    "<exceptions>\n",
    "{format_exceptions(eval_item.event.exceptions)}\n",
    "</exceptions>\n",
    "</issue>\n",
    "\n",
    "Given the above issue, we know the correct fix is:\n",
    "\n",
    "<expected_solution>\n",
    "<description>\n",
    "{eval_item.commit.commit.message}\n",
    "</description>\n",
    "<changes>\n",
    "{eval_item.diff}\n",
    "</changes>\n",
    "</expected_solution>\n",
    "\n",
    "The model outputted the following solution:\n",
    "\n",
    "<predicted_solution>\n",
    "{predicted_output.diff_str}\n",
    "</predicted_solution>\n",
    "\n",
    "Score how well the predicted solution matches the expected solution with a float score from 0 to 1, where 1 means the solution fully fixes the issue and 0 means the solution does not fix the issue at all.\n",
    "- Consider the context of the issue and the diff\n",
    "- Consider that there are multiple ways to fix an issue\n",
    "- Return the score inside a <score> tag.\"\"\")\n",
    "\n",
    "score_fix(item, autofix_result[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
